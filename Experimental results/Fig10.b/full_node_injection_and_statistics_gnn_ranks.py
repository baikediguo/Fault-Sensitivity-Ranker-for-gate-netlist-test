# full_node_injection_and_statistics_gnn_ranks.py
# ä¸¤é˜¶æ®µæ•…éšœæ³¨å…¥ä¸ç»Ÿè®¡è„šæœ¬
# é˜¶æ®µ1ï¼šå¯¹ç½‘è¡¨æ‰€æœ‰èŠ‚ç‚¹è¿›è¡Œæ•…éšœæ³¨å…¥ï¼Œä¿å­˜æµ‹è¯•ç»“æœ
# é˜¶æ®µ2ï¼šæ ¹æ®ä¿å­˜çš„ç»“æœï¼Œå¯¹ä¸åŒgnn_rankæ–‡ä»¶çš„è¦†ç›–ç‡è¿›è¡Œç»Ÿè®¡
# ä½¿ç”¨ gnn_ranks ç›®å½•ï¼ˆæ–‡ä»¶åæ ¼å¼ï¼šgnn_rank_{topk}.txtï¼‰

import os
import re
import csv
import time
import json
import subprocess
from typing import List, Tuple, Set, Dict
import glob
from collections import defaultdict
import math

## ===== åŸºæœ¬é…ç½® =====
VERILOG_SRC = 'pe.synth_dct.v'    # ç½‘è¡¨
TB_FILE     = 'tb_1.v'              # testbench
CELL_LIB    = 'cells.v'           # å·¥è‰ºåº“
RANK_DIR    = 'gnn_ranks'          # å­˜æ”¾å¤šä¸ª gnn_rank_xxx.txt çš„ç›®å½•

# æ—¥å¿—&ä¸´æ—¶æ–‡ä»¶ç›®å½•
LOGDIR = 'sim_logs_full_injection'
os.makedirs(LOGDIR, exist_ok=True)

# å…¨èŠ‚ç‚¹æ³¨å…¥ç»“æœä¿å­˜ç›®å½•
RESULTS_DIR = 'full_injection_results'
os.makedirs(RESULTS_DIR, exist_ok=True)

# æ³¨å…¥æ—¶åºé…ç½®
INJECT_DELAY_CYCLES = 5
MAX_VVP_SECONDS     = 60

# è¾“å‡ºåŒ¹é…æ¨¡å¼
OSUM_HEX_RE = re.compile(r'^o_sum=([0-9a-fA-FxzXZ]+)')

# å…è®¸çš„æœªçŸ¥æ¯”ä¾‹
MAX_UNKNOWN_RATIO = 0.2


# ========== å·¥å…·å‡½æ•° ==========

def run_cmd(cmd: List[str], capture=False, timeout=None) -> Tuple[int, str]:
    """æ‰§è¡Œå‘½ä»¤ï¼Œåœ¨ Windows ä¸‹ç”¨ UTF-8 å¹¶å¿½ç•¥ä¸èƒ½è§£ç çš„å­—ç¬¦"""
    if capture:
        proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT,
                                text=True, encoding='utf-8', errors='ignore')
        try:
            out, _ = proc.communicate(timeout=timeout)
        except subprocess.TimeoutExpired:
            proc.kill()
            return -1, 'TIMEOUT'
        return proc.returncode, out
    else:
        try:
            rc = subprocess.call(cmd)
            return rc, ''
        except Exception as e:
            return -1, str(e)


def strip_comments(text: str) -> str:
    """å»é™¤ Verilog æ³¨é‡Š"""
    text = re.sub(r'/\*.*?\*/', '', text, flags=re.DOTALL)
    text = re.sub(r'//.*', '', text)
    return text


def extract_module(text: str, modname: str) -> str:
    """æå–æ¨¡å—å®šä¹‰"""
    m = re.search(rf'\bmodule\s+{re.escape(modname)}\b.*?\bendmodule\b', text, flags=re.DOTALL)
    return m.group(0) if m else ''


def split_decl_names(decl_body: str) -> List[str]:
    """æ‹†åˆ†å£°æ˜ä¸­çš„ä¿¡å·å"""
    out = []
    decl_body = re.sub(r'\[[^]\n]*:[^]\n]*\]', '', decl_body)
    for chunk in decl_body.split(','):
        token = chunk.strip()
        if not token:
            continue
        m = re.match(r'^([A-Za-z_][A-Za-z0-9_$]*)(\[\d+\])?$', token)
        if m:
            out.append(m.group(0))
    return out


def parse_ports(module_text: str) -> Tuple[Set[str], Set[str], Set[str]]:
    """è§£ææ¨¡å—çš„è¾“å…¥ã€è¾“å‡ºã€åŒå‘ç«¯å£"""
    inputs, outputs, inouts = set(), set(), set()
    for stmt in module_text.split(';'):
        s = stmt.strip()
        if not s: continue
        if re.match(r'^\binput\b', s):
            body = re.sub(r'^\binput\b\s+((?:wire|reg|logic|signed|unsigned)\s+)*', '', s)
            inputs.update(split_decl_names(body))
        elif re.match(r'^\boutput\b', s):
            body = re.sub(r'^\boutput\b\s+((?:wire|reg|logic|signed|unsigned)\s+)*', '', s)
            outputs.update(split_decl_names(body))
        elif re.match(r'^\binout\b', s):
            body = re.sub(r'^\binout\b\s+((?:wire|reg|logic|signed|unsigned)\s+)*', '', s)
            inouts.update(split_decl_names(body))
    return inputs, outputs, inouts


def parse_internal_nets(module_text: str) -> Set[str]:
    """è§£ææ¨¡å—å†…éƒ¨çš„ wire/reg ä¿¡å·"""
    nets = set()
    for stmt in module_text.split(';'):
        s = stmt.strip()
        if not s: continue
        if re.match(r'^(wire|reg|logic)\b', s):
            body = re.sub(r'^(wire|reg|logic)\b\s+((?:signed|unsigned)\s+)?', '', s)
            nets.update(split_decl_names(body))
    return nets


def parse_targets_from_netlist(netlist_text: str, dut_module: str = 'pe') -> List[str]:
    """
    è§£æå¯æ³¨å…¥ç›®æ ‡ï¼šè¾“å‡ºç«¯å£ âˆª å†…éƒ¨ nets âˆ’ è¾“å…¥ç«¯å£
    ä»…ä¿ç•™å¯ force çš„åˆæ³•åå­—ï¼ˆID æˆ– ID[NUM]ï¼‰
    """
    text = strip_comments(netlist_text)
    mod = extract_module(text, dut_module)
    if not mod:
        mod = text
    inputs, outputs, _ = parse_ports(mod)
    internals = parse_internal_nets(mod)
    targets = (outputs | internals) - inputs

    good = []
    for n in sorted(targets):
        if re.match(r'^[A-Za-z_][A-Za-z0-9_$]*$', n) or re.match(r'^[A-Za-z_][A-Za-z0-9_$]*\[\d+\]$', n):
            good.append(n)
    return good


def make_injected_tb(tb_text: str, target_net: str, stuck: int) -> str:
    """ç”Ÿæˆå¸¦æ•…éšœæ³¨å…¥çš„ testbench"""
    inj_block = f"""
// --- fault injection block (auto) ---
initial begin : __fi_block
    wait (reset == 0);
    repeat({INJECT_DELAY_CYCLES}) @(posedge clock);
    force uut.{target_net} = 1'b{stuck};
    $display("FAULT_INJECTED: {target_net} sa{stuck}");
end
// --- end injection block ---
"""
    idx = tb_text.rfind('endmodule')
    if idx == -1:
        return tb_text + '\n' + inj_block
    else:
        return tb_text[:idx] + inj_block + tb_text[idx:]


def compile_and_run(sources: List[str], exe_path: str, vcd_path: str, log_path: str,
                    timeout: int = MAX_VVP_SECONDS) -> bool:
    """
    Icarus Verilog ç¼–è¯‘å’Œè¿è¡Œæµç¨‹
    è¿”å› True/False è¡¨ç¤ºæˆåŠŸ/å¤±è´¥
    """
    # ç¼–è¯‘
    cmd_compile = ['iverilog', '-g2012', '-o', exe_path] + [os.path.abspath(s) for s in sources]
    rc, out = run_cmd(cmd_compile, capture=True)
    if rc != 0:
        with open(log_path, 'w', encoding='utf-8', errors='ignore') as f:
            f.write(out)
        return False

    # è¿è¡Œ
    cmd_run = ['vvp', exe_path, f'+DUMPFILE={vcd_path}']
    with open(log_path, 'w', encoding='utf-8', errors='ignore') as f:
        try:
            proc = subprocess.Popen(cmd_run, stdout=f, stderr=subprocess.STDOUT,
                                    text=True, encoding='utf-8', errors='ignore')
            proc.wait(timeout=timeout)
        except subprocess.TimeoutExpired:
            proc.kill()
            f.write('\n[ERROR] vvp TIMEOUT\n')
            return False

    return True


def parse_osum_as_ints(logfile: str) -> Tuple[List[int], float]:
    """ä»æ—¥å¿—æ–‡ä»¶ä¸­è§£æ o_sum è¾“å‡ºå€¼"""
    vals, total, unknown = [], 0, 0
    try:
        with open(logfile, 'r', encoding='utf-8', errors='ignore') as f:
            for line in f:
                m = OSUM_HEX_RE.match(line.strip())
                if not m:
                    continue
                total += 1
                s = m.group(1).lower()
                if 'x' in s or 'z' in s:
                    unknown += 1
                    continue
                try:
                    vals.append(int(s, 16))
                except ValueError:
                    unknown += 1
    except Exception as e:
        print(f'âš ï¸ è¯»å– {logfile} å¤±è´¥: {e}')
    unk_ratio = (unknown / total) if total > 0 else 1.0
    return vals, unk_ratio


def calculate_rmse(golden_vals: List[int], faulty_vals: List[int]) -> Tuple[float, int]:
    """
    è®¡ç®— RMSE (Root Mean Square Error) between golden and faulty outputs
    
    Args:
        golden_vals: Golden reference values
        faulty_vals: Faulty simulation values
    
    Returns:
        - RMSE value (float)
        - Number of valid comparison points
    """
    if not golden_vals or not faulty_vals:
        return float('nan'), 0
    
    # Use minimum length to ensure valid comparison
    n = min(len(golden_vals), len(faulty_vals))
    
    if n == 0:
        return float('nan'), 0
    
    # Calculate squared differences
    squared_diffs = [(float(g) - float(f)) ** 2 for g, f in zip(golden_vals[:n], faulty_vals[:n])]
    
    # Calculate mean squared error
    mse = sum(squared_diffs) / n
    
    # Calculate RMSE
    rmse = math.sqrt(mse)
    
    return rmse, n


def load_gnn_topk(path: str, topk: int) -> List[str]:
    """ä» gnn_rank æ–‡ä»¶ä¸­è¯»å–å‰ topk ä¸ªèŠ‚ç‚¹"""
    if not os.path.exists(path):
        print(f'âŒ æœªæ‰¾åˆ° {path}')
        return []
    nodes = []
    with open(path, 'r', encoding='utf-8', errors='ignore') as f:
        for line in f:
            line = line.strip()
            if not line: continue
            parts = line.split()
            if len(parts) >= 1:
                nodes.append(parts[0])
    return nodes[:topk]


def extract_topk(filename: str):
    """ä»æ–‡ä»¶åæå– TopK æ•°å­—ï¼Œä¾‹å¦‚ gnn_rank_50.txt -> 50
    å¦‚æœæ–‡ä»¶åæ˜¯ gnn_rank.txtï¼ˆæ²¡æœ‰ä¸‹åˆ’çº¿ï¼‰ï¼Œè¿”å› None
    """
    # æå–çº¯æ–‡ä»¶åï¼ˆä¸å«è·¯å¾„ï¼‰
    basename = os.path.basename(filename)
    
    # æ”¯æŒæ ¼å¼ï¼šgnn_rank_50.txt
    m = re.search(r'gnn_rank_(\d+)\.txt', basename)
    if m:
        return int(m.group(1))
    # æ”¯æŒ gnn_rank_all.txt æ ¼å¼
    m2 = re.search(r'gnn_rank_all\.txt', basename)
    if m2:
        return float('inf')  # è¡¨ç¤ºå…¨éƒ¨èŠ‚ç‚¹
    # æ”¯æŒ gnn_rank.txt æ ¼å¼ï¼ˆæ²¡æœ‰ä¸‹åˆ’çº¿ï¼‰
    if basename == 'gnn_rank.txt':
        return None  # è¡¨ç¤ºæ™®é€šæ’åæ–‡ä»¶ï¼ŒèŠ‚ç‚¹æ•°æœªçŸ¥
    return float('inf')


# ========== é˜¶æ®µ1ï¼šå…¨èŠ‚ç‚¹æ³¨å…¥ ==========

def phase1_full_node_injection():
    """
    é˜¶æ®µ1ï¼šå¯¹ç½‘è¡¨æ‰€æœ‰èŠ‚ç‚¹è¿›è¡Œæ•…éšœæ³¨å…¥æµ‹è¯•ï¼Œå¹¶ä¿å­˜æ¯ä¸ªèŠ‚ç‚¹çš„æµ‹è¯•ç»“æœ
    è¿”å›ï¼šgolden å€¼åˆ—è¡¨å’Œå…¨èŠ‚ç‚¹æµ‹è¯•ç»“æœå­—å…¸
    """
    print('\n' + '='*70)
    print('é˜¶æ®µ1ï¼šå…¨èŠ‚ç‚¹æ•…éšœæ³¨å…¥æµ‹è¯•')
    print('='*70)
    
    t0_phase1 = time.time()
    
    # 1) ç”Ÿæˆ golden åŸºå‡†
    print('\n[1/3] è¿è¡Œ golden ä»¿çœŸï¼ˆæ— æ•…éšœåŸºå‡†ï¼‰...')
    golden_exe = os.path.join(LOGDIR, 'golden.out')
    golden_vcd = os.path.join(LOGDIR, 'golden.vcd')
    golden_log = os.path.join(LOGDIR, 'golden.log')
    ok = compile_and_run([CELL_LIB, VERILOG_SRC, TB_FILE],
                         golden_exe, golden_vcd, golden_log,
                         timeout=MAX_VVP_SECONDS)
    if not ok:
        print('âŒ Golden ä»¿çœŸå¤±è´¥')
        with open(golden_log, 'r', encoding='utf-8', errors='ignore') as f:
            print(f.read())
        return None, None
    
    golden_vals, golden_unk = parse_osum_as_ints(golden_log)
    if not golden_vals:
        print('âŒ golden.log æ²¡æœ‰æœ‰æ•ˆçš„ o_sum æ ·æœ¬')
        return None, None
    print(f'âœ… Golden æ ·æœ¬æ•°: {len(golden_vals)}, Unknownæ¯”ä¾‹: {golden_unk:.2%}')
    
    # ä¿å­˜ golden ç»“æœ
    golden_result_file = os.path.join(RESULTS_DIR, 'golden_result.json')
    with open(golden_result_file, 'w', encoding='utf-8') as f:
        json.dump({
            'values': golden_vals,
            'unknown_ratio': golden_unk,
            'sample_count': len(golden_vals)
        }, f, indent=2)
    print(f'âœ… Golden ç»“æœå·²ä¿å­˜: {golden_result_file}')
    
    # 2) è§£ææ‰€æœ‰å¯æ³¨å…¥çš„åˆæ³•èŠ‚ç‚¹
    print('\n[2/3] è§£æç½‘è¡¨ä¸­çš„å¯æ³¨å…¥èŠ‚ç‚¹...')
    with open(VERILOG_SRC, 'r', encoding='utf-8', errors='ignore') as f:
        net_text = f.read()
    all_targets = parse_targets_from_netlist(net_text, dut_module='pe')
    
    # è¿‡æ»¤æ‰æ—¶é’Ÿå’Œå¤ä½ä¿¡å·
    legal_targets = [n for n in all_targets 
                     if not re.match(r'^(clk|clock|rst|reset)', n, flags=re.IGNORECASE)]
    
    print(f'âœ… å…±æ‰¾åˆ° {len(legal_targets)} ä¸ªå¯æ³¨å…¥èŠ‚ç‚¹ï¼ˆå·²è¿‡æ»¤æ—¶é’Ÿå’Œå¤ä½ä¿¡å·ï¼‰')
    
    # ä¿å­˜èŠ‚ç‚¹åˆ—è¡¨
    nodes_list_file = os.path.join(RESULTS_DIR, 'all_nodes.txt')
    with open(nodes_list_file, 'w', encoding='utf-8') as f:
        for node in legal_targets:
            f.write(f'{node}\n')
    print(f'âœ… èŠ‚ç‚¹åˆ—è¡¨å·²ä¿å­˜: {nodes_list_file}')
    
    # 3) å¯¹æ¯ä¸ªèŠ‚ç‚¹è¿›è¡Œ SA0 å’Œ SA1 æ³¨å…¥
    print('\n[3/3] å¼€å§‹å…¨èŠ‚ç‚¹æ³¨å…¥æµ‹è¯•...')
    print(f'æ€»å…±éœ€è¦æµ‹è¯•: {len(legal_targets)} ä¸ªèŠ‚ç‚¹ Ã— 2 ç§æ•…éšœç±»å‹ = {len(legal_targets)*2} æ¬¡ä»¿çœŸ')
    
    tb_src = open(TB_FILE, 'r', encoding='utf-8', errors='ignore').read()
    
    # å­˜å‚¨æ¯ä¸ªèŠ‚ç‚¹çš„æµ‹è¯•ç»“æœ
    node_results = {}  # {node_name: {'sa0': {...}, 'sa1': {...}}}
    
    total_tests = len(legal_targets) * 2
    current_test = 0
    
    for i, net in enumerate(legal_targets, 1):
        node_results[net] = {'sa0': None, 'sa1': None}
        
        for val in [0, 1]:
            current_test += 1
            fault_type = f'sa{val}'
            
            # æ˜¾ç¤ºè¿›åº¦
            if current_test % 100 == 0 or current_test == total_tests:
                elapsed = time.time() - t0_phase1
                progress = current_test / total_tests * 100
                print(f'  è¿›åº¦: [{current_test}/{total_tests}] ({progress:.1f}%) '
                      f'å½“å‰èŠ‚ç‚¹: {net} {fault_type} - å·²ç”¨æ—¶: {elapsed:.1f}s')
            
            # ç”Ÿæˆæ³¨å…¥ testbench
            tb_inj = make_injected_tb(tb_src, net, val)
            tb_tmp = os.path.join(LOGDIR, f'tb_inj_{i}_{fault_type}.v')
            with open(tb_tmp, 'w', encoding='utf-8', errors='ignore') as w:
                w.write(tb_inj)
            
            # ç¼–è¯‘å’Œè¿è¡Œ
            exe = os.path.join(LOGDIR, f'sim_{i}_{fault_type}.out')
            vcd = os.path.join(LOGDIR, f'sim_{i}_{fault_type}.vcd')
            log = os.path.join(LOGDIR, f'sim_{i}_{fault_type}.log')
            
            ok = compile_and_run([CELL_LIB, VERILOG_SRC, tb_tmp], 
                                exe, vcd, log, timeout=MAX_VVP_SECONDS)
            
            if not ok:
                node_results[net][fault_type] = {
                    'status': 'compile_fail',
                    'detected': False,
                    'values': [],
                    'unknown_ratio': 1.0
                }
                continue
            
            # è§£æç»“æœ
            vals, unk = parse_osum_as_ints(log)
            
            if not vals or unk > MAX_UNKNOWN_RATIO:
                node_results[net][fault_type] = {
                    'status': 'invalid_output',
                    'detected': False,
                    'values': vals,
                    'unknown_ratio': unk
                }
                continue
            
            # å¯¹æ¯” golden å€¼åˆ¤æ–­æ˜¯å¦æ£€æµ‹åˆ°æ•…éšœ
            L = min(len(golden_vals), len(vals))
            diff_count = sum(1 for a, b in zip(golden_vals[:L], vals[:L]) if a != b)
            detected = diff_count > 0
            
            # è®¡ç®— RMSE
            rmse, valid_points = calculate_rmse(golden_vals, vals)
            
            node_results[net][fault_type] = {
                'status': 'success',
                'detected': detected,
                'diff_count': diff_count,
                'sample_count': L,
                'values': vals,
                'unknown_ratio': unk,
                'rmse': rmse,
                'rmse_valid_points': valid_points
            }
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶ï¼ˆä¿ç•™ logï¼Œåˆ é™¤ exe å’Œ vcdï¼‰
            try:
                if os.path.exists(tb_tmp):
                    os.remove(tb_tmp)
                if os.path.exists(exe):
                    os.remove(exe)
                if os.path.exists(vcd):
                    os.remove(vcd)
            except Exception as e:
                pass
    
    # ä¿å­˜å®Œæ•´æµ‹è¯•ç»“æœ
    results_file = os.path.join(RESULTS_DIR, 'full_injection_results.json')
    print(f'\nä¿å­˜æµ‹è¯•ç»“æœåˆ°: {results_file}')
    with open(results_file, 'w', encoding='utf-8') as f:
        # ç”±äºç»“æœå¯èƒ½å¾ˆå¤§ï¼Œä¸ä¿å­˜å…·ä½“çš„ valuesï¼Œåªä¿å­˜æ£€æµ‹çŠ¶æ€å’ŒRMSE
        simplified_results = {}
        for node, faults in node_results.items():
            simplified_results[node] = {
                'sa0': {k: v for k, v in faults['sa0'].items() if k != 'values'} if faults['sa0'] else None,
                'sa1': {k: v for k, v in faults['sa1'].items() if k != 'values'} if faults['sa1'] else None
            }
        json.dump(simplified_results, f, indent=2)
    
    # ä¿å­˜ RMSE ä¸“é—¨çš„ CSV æ–‡ä»¶
    rmse_csv_file = os.path.join(RESULTS_DIR, 'rmse_results.csv')
    print(f'ä¿å­˜ RMSE ç»“æœåˆ°: {rmse_csv_file}')
    
    rmse_data = []
    for node, faults in node_results.items():
        for fault_type in ['sa0', 'sa1']:
            fault_result = faults.get(fault_type)
            if fault_result and fault_result.get('status') == 'success':
                rmse_value = fault_result.get('rmse', float('nan'))
                rmse_data.append({
                    'node_name': node,
                    'stuck_at': fault_type.replace('sa', ''),
                    'rmse': rmse_value,
                    'valid_points': fault_result.get('rmse_valid_points', 0),
                    'diff_count': fault_result.get('diff_count', 0),
                    'detected': 'Yes' if fault_result.get('detected', False) else 'No'
                })
    
    # æŒ‰ RMSE é™åºæ’åº
    rmse_data_sorted = sorted(rmse_data, 
                              key=lambda x: x['rmse'] if not math.isnan(x['rmse']) else -1, 
                              reverse=True)
    
    with open(rmse_csv_file, 'w', newline='', encoding='utf-8') as f:
        fieldnames = ['node_name', 'stuck_at', 'rmse', 'valid_points', 'diff_count', 'detected']
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        
        for data in rmse_data_sorted:
            writer.writerow({
                'node_name': data['node_name'],
                'stuck_at': data['stuck_at'],
                'rmse': f"{data['rmse']:.4f}" if not math.isnan(data['rmse']) else 'N/A',
                'valid_points': data['valid_points'],
                'diff_count': data['diff_count'],
                'detected': data['detected']
            })
    
    # ç»Ÿè®¡æ±‡æ€»
    total_nodes = len(legal_targets)
    total_faults = total_nodes * 2
    detected_nodes = 0
    detected_faults = 0
    
    for node, faults in node_results.items():
        node_detected = False
        for fault_type in ['sa0', 'sa1']:
            if faults[fault_type] and faults[fault_type].get('detected', False):
                detected_faults += 1
                node_detected = True
        if node_detected:
            detected_nodes += 1
    
    # RMSE ç»Ÿè®¡
    valid_rmse_values = [data['rmse'] for data in rmse_data if not math.isnan(data['rmse'])]
    
    elapsed_phase1 = time.time() - t0_phase1
    
    print('\n' + '='*70)
    print('é˜¶æ®µ1 å®Œæˆ - å…¨èŠ‚ç‚¹æ³¨å…¥æµ‹è¯•ç»Ÿè®¡')
    print('='*70)
    print(f'æ€»æµ‹è¯•èŠ‚ç‚¹æ•°: {total_nodes}')
    print(f'æ€»æµ‹è¯•æ•…éšœæ•°: {total_faults}')
    print(f'æ£€æµ‹åˆ°çš„èŠ‚ç‚¹æ•°: {detected_nodes} ({detected_nodes/total_nodes*100:.2f}%)')
    print(f'æ£€æµ‹åˆ°çš„æ•…éšœæ•°: {detected_faults} ({detected_faults/total_faults*100:.2f}%)')
    
    if valid_rmse_values:
        print(f'\nğŸ“Š RMSE ç»Ÿè®¡:')
        print(f'   æœ‰æ•ˆ RMSE è®¡ç®—æ•°: {len(valid_rmse_values)}')
        print(f'   æœ€å¤§ RMSE: {max(valid_rmse_values):.4f}')
        print(f'   æœ€å° RMSE: {min(valid_rmse_values):.4f}')
        print(f'   å¹³å‡ RMSE: {sum(valid_rmse_values)/len(valid_rmse_values):.4f}')
        
        # è®¡ç®—ä¸´ç•Œæ•…éšœæ•°ï¼ˆRMSE > 1000ï¼‰
        RMSE_THRESHOLD = 1000.0
        critical_count = sum(1 for r in valid_rmse_values if r > RMSE_THRESHOLD)
        print(f'   ä¸´ç•Œæ•…éšœ (RMSE > {RMSE_THRESHOLD}): {critical_count} ({critical_count/len(valid_rmse_values)*100:.2f}%)')
    
    print(f'\né˜¶æ®µ1æ€»ç”¨æ—¶: {elapsed_phase1:.2f}s')
    print('='*70)
    
    return golden_vals, node_results


# ========== é˜¶æ®µ2ï¼šåŸºäºä¿å­˜ç»“æœçš„è¦†ç›–ç‡ç»Ÿè®¡ ==========

def phase2_coverage_statistics(golden_vals: List[int], node_results: Dict):
    """
    é˜¶æ®µ2ï¼šæ ¹æ®ä¿å­˜çš„å…¨èŠ‚ç‚¹æµ‹è¯•ç»“æœï¼Œå¯¹ä¸åŒ gnn_rank æ–‡ä»¶çš„è¦†ç›–ç‡è¿›è¡Œç»Ÿè®¡
    gnn_ranks ç›®å½•ä¸‹çš„æ–‡ä»¶æ ¼å¼ï¼šgnn_rank_{topk}.txtï¼ˆæ²¡æœ‰ run åç¼€ï¼‰
    å¦‚æœåªæœ‰ä¸€ä¸ªæ–‡ä»¶ï¼ŒæŒ‰èŠ‚ç‚¹æ•°é€’å¢è¾“å‡ºç´¯ç§¯è¦†ç›–ç‡
    """
    print('\n' + '='*70)
    print('é˜¶æ®µ2ï¼šåŸºäºå…¨èŠ‚ç‚¹ç»“æœçš„è¦†ç›–ç‡ç»Ÿè®¡')
    print('='*70)
    
    t0_phase2 = time.time()
    
    # 1) æŸ¥æ‰¾æ‰€æœ‰ gnn_rank æ–‡ä»¶
    print('\n[1/2] æŸ¥æ‰¾ gnn_rank æ–‡ä»¶...')
    # æŸ¥æ‰¾ gnn_rank_*.txt æ ¼å¼çš„æ–‡ä»¶
    rank_files = glob.glob(os.path.join(RANK_DIR, "gnn_rank_*.txt"))
    # ä¹ŸæŸ¥æ‰¾ gnn_rank.txt æ ¼å¼çš„æ–‡ä»¶ï¼ˆæ²¡æœ‰ä¸‹åˆ’çº¿ï¼‰
    rank_file_plain = os.path.join(RANK_DIR, "gnn_rank.txt")
    if os.path.exists(rank_file_plain) and rank_file_plain not in rank_files:
        rank_files.append(rank_file_plain)
    
    if not rank_files:
        print(f'âŒ {RANK_DIR} ä¸‹æ²¡æœ‰æ‰¾åˆ° gnn_rank æ–‡ä»¶ï¼ˆæ”¯æŒ gnn_rank.txt æˆ– gnn_rank_*.txtï¼‰')
        return
    
    # å¦‚æœåªæœ‰ä¸€ä¸ªæ–‡ä»¶ï¼Œä½¿ç”¨ç´¯ç§¯ç»Ÿè®¡æ¨¡å¼
    if len(rank_files) == 1:
        rank_file = rank_files[0]
        filename = os.path.basename(rank_file)
        print(f'âœ… æ‰¾åˆ° 1 ä¸ª gnn_rank æ–‡ä»¶: {filename}')
        print('\n[2/2] æŒ‰èŠ‚ç‚¹æ•°é€’å¢ç»Ÿè®¡ç´¯ç§¯è¦†ç›–ç‡...')
        
        # è¯»å–æ‰€æœ‰èŠ‚ç‚¹
        gnn_nodes = load_gnn_topk(rank_file, topk=10**9)
        
        # è¿‡æ»¤ï¼šåªä¿ç•™åœ¨ node_results ä¸­çš„èŠ‚ç‚¹
        filtered_nodes = [n for n in gnn_nodes if n in node_results]
        
        if not filtered_nodes:
            print(f'âŒ æ²¡æœ‰åŒ¹é…çš„èŠ‚ç‚¹')
            return
        
        print(f'âœ… æœ‰æ•ˆèŠ‚ç‚¹æ•°: {len(filtered_nodes)}')
        print('\nå¼€å§‹é€’å¢ç»Ÿè®¡ï¼ˆä»1ä¸ªèŠ‚ç‚¹å¼€å§‹ï¼Œé€æ­¥å¢åŠ åˆ°æ‰€æœ‰èŠ‚ç‚¹ï¼‰...\n')
        
        results = []  # åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä¸ºç´¯ç§¯ç»Ÿè®¡ç»“æœ
        
        # ä»1ä¸ªèŠ‚ç‚¹å¼€å§‹ï¼Œé€æ­¥å¢åŠ åˆ°æ‰€æœ‰èŠ‚ç‚¹
        for num_nodes in range(1, len(filtered_nodes) + 1):
            # å–å‰ num_nodes ä¸ªèŠ‚ç‚¹ï¼ˆç´¯ç§¯ï¼‰
            current_nodes = filtered_nodes[:num_nodes]
            
            # ç»Ÿè®¡ç´¯ç§¯è¦†ç›–ç‡å’ŒRMSE
            detected_nodes = 0
            detected_faults = 0
            rmse_values = []
            
            for node in current_nodes:
                node_detected = False
                for fault_type in ['sa0', 'sa1']:
                    fault_result = node_results[node].get(fault_type)
                    if fault_result and fault_result.get('detected', False):
                        detected_faults += 1
                        node_detected = True
                    # æ”¶é›† RMSE å€¼
                    if fault_result and fault_result.get('status') == 'success':
                        rmse_val = fault_result.get('rmse', float('nan'))
                        if not math.isnan(rmse_val):
                            rmse_values.append(rmse_val)
                if node_detected:
                    detected_nodes += 1
            
            # è®¡ç®—ç´¯ç§¯è¦†ç›–ç‡
            total_faults = len(current_nodes) * 2
            node_cov = detected_nodes / len(current_nodes) * 100.0 if current_nodes else 0
            fault_cov = detected_faults / total_faults * 100.0 if total_faults else 0
            
            # è®¡ç®—å¹³å‡RMSE
            avg_rmse = sum(rmse_values) / len(rmse_values) if rmse_values else 0.0
            max_rmse = max(rmse_values) if rmse_values else 0.0
            
            results.append({
                'num_nodes': num_nodes,
                'fault_cov': fault_cov,
                'node_cov': node_cov,
                'tested_nodes': len(current_nodes),
                'detected_nodes': detected_nodes,
                'detected_faults': detected_faults,
                'avg_rmse': avg_rmse,
                'max_rmse': max_rmse,
                'rmse_count': len(rmse_values)
            })
            
            # å®æ—¶è¾“å‡ºå½“å‰ç»“æœ
            escaped_nodes = len(current_nodes) - detected_nodes
            escaped_faults = total_faults - detected_faults
            print(f'èŠ‚ç‚¹æ•°={num_nodes:4d}: èŠ‚ç‚¹è¦†ç›–ç‡={node_cov:6.2f}%, æ•…éšœè¦†ç›–ç‡={fault_cov:6.2f}%, '
                  f'æ£€æµ‹èŠ‚ç‚¹={detected_nodes:4d}, æ£€æµ‹æ•…éšœ={detected_faults:4d}, '
                  f'é€ƒé€¸èŠ‚ç‚¹={escaped_nodes:4d}, é€ƒé€¸æ•…éšœ={escaped_faults:4d}, '
                  f'å¹³å‡RMSE={avg_rmse:.4f}')
        
        # ä¿å­˜ç»Ÿè®¡ç»“æœåˆ° CSV
        RESULT_CSV = os.path.join(RESULTS_DIR, 'coverage_statistics.csv')
        print(f'\nä¿å­˜ç»Ÿè®¡ç»“æœåˆ°: {RESULT_CSV}')
        
        with open(RESULT_CSV, 'w', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            
            # å†™å…¥åˆ—æ ‡é¢˜
            header = ['num_nodes', 'tested_nodes', 'fault_coverage(%)', 'node_coverage(%)', 
                     'avg_rmse', 'max_rmse', 'detected_nodes', 'detected_faults', 
                     'escaped_nodes', 'escaped_faults']
            writer.writerow(header)
            
            # å†™å…¥æ¯ä¸ªèŠ‚ç‚¹æ•°çš„ç´¯ç§¯æ•°æ®
            for result in results:
                tested_nodes = result['tested_nodes']
                detected_nodes = result['detected_nodes']
                detected_faults = result['detected_faults']
                
                # è®¡ç®—é€ƒé€¸èŠ‚ç‚¹å’Œé€ƒé€¸æ•…éšœ
                escaped_nodes = tested_nodes - detected_nodes
                injected_faults = tested_nodes * 2
                escaped_faults = injected_faults - detected_faults
                
                row = [
                    result['num_nodes'],
                    tested_nodes,
                    f"{result['fault_cov']:.2f}",
                    f"{result['node_cov']:.2f}",
                    f"{result['avg_rmse']:.4f}",
                    f"{result['max_rmse']:.4f}",
                    str(detected_nodes),
                    str(detected_faults),
                    str(escaped_nodes),
                    str(escaped_faults)
                ]
                writer.writerow(row)
        
        elapsed_phase2 = time.time() - t0_phase2
        
        # è¾“å‡ºæœ€ç»ˆç»Ÿè®¡
        final_result = results[-1]
        print('\n' + '='*70)
        print('é˜¶æ®µ2 å®Œæˆ - ç´¯ç§¯è¦†ç›–ç‡ç»Ÿè®¡')
        print('='*70)
        print(f'æ€»èŠ‚ç‚¹æ•°: {len(filtered_nodes)}')
        print(f'æœ€ç»ˆèŠ‚ç‚¹è¦†ç›–ç‡: {final_result["node_cov"]:.2f}%')
        print(f'æœ€ç»ˆæ•…éšœè¦†ç›–ç‡: {final_result["fault_cov"]:.2f}%')
        print(f'æœ€ç»ˆæ£€æµ‹èŠ‚ç‚¹æ•°: {final_result["detected_nodes"]}')
        print(f'æœ€ç»ˆæ£€æµ‹æ•…éšœæ•°: {final_result["detected_faults"]}')
        print(f'ç»“æœæ–‡ä»¶: {RESULT_CSV}')
        print(f'\né˜¶æ®µ2ç”¨æ—¶: {elapsed_phase2:.2f}s')
        print('='*70)
        
        return
    
    # å¤šä¸ªæ–‡ä»¶çš„æƒ…å†µï¼šæŒ‰ topk åˆ†ç»„å¤„ç†ï¼ˆåŸæœ‰é€»è¾‘ï¼‰
    # æŒ‰ topk åˆ†ç»„
    files_by_topk = {}  # {topk: [filepath]}
    plain_files = []  # å­˜å‚¨ gnn_rank.txt æ ¼å¼çš„æ–‡ä»¶
    for filepath in rank_files:
        filename = os.path.basename(filepath)
        topk = extract_topk(filename)
        if topk is None:
            # gnn_rank.txt æ ¼å¼çš„æ–‡ä»¶
            plain_files.append(filepath)
        elif topk != float('inf'):
            if topk not in files_by_topk:
                files_by_topk[topk] = []
            files_by_topk[topk].append(filepath)
    
    # å¦‚æœæœ‰ gnn_rank.txt æ ¼å¼çš„æ–‡ä»¶ï¼Œä¹Ÿæ·»åŠ åˆ°å¤„ç†åˆ—è¡¨
    if plain_files:
        # ä½¿ç”¨ None ä½œä¸º key è¡¨ç¤ºæ™®é€šæ’åæ–‡ä»¶
        if None not in files_by_topk:
            files_by_topk[None] = []
        files_by_topk[None].extend(plain_files)
    
    # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
    # è‡ªå®šä¹‰æ’åºï¼šNone æ”¾åœ¨æœ€åï¼Œå…¶ä»–æŒ‰æ•°å­—æ’åº
    def sort_key(item):
        topk = item[0] if isinstance(item, tuple) else item
        if topk is None:
            return (1, 0)  # None æ”¾åœ¨æœ€å
        elif isinstance(topk, (int, float)):
            return (0, topk)  # æ•°å­—æ­£å¸¸æ’åº
        else:
            return (2, 0)  # å…¶ä»–ç±»å‹æ”¾åœ¨æœ€å
    
    for topk, files in sorted(files_by_topk.items(), key=sort_key):
        topk_display = 'all' if topk == float('inf') else (topk if topk is not None else 'plain')
        print(f'  TopK={topk_display}: æ‰¾åˆ° {len(files)} ä¸ªæ’åæ–‡ä»¶')
    
    if not files_by_topk:
        print('âŒ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„æ’åæ–‡ä»¶')
        return
    
    # ä½¿ç”¨ files_by_topk çš„ key ç¡®ä¿ä¸€è‡´æ€§ï¼Œè¿›è¡Œæ’åº
    topk_list = sorted([k for k in files_by_topk.keys()], 
                       key=lambda x: (1, 0) if x is None else ((0, x) if isinstance(x, (int, float)) else (2, 0)))
    print(f'âœ… æ‰¾åˆ° {len(topk_list)} ä¸ª topk å€¼: {[str(x) if x is not None else "plain" for x in topk_list]}')
    
    # 2) å¯¹æ¯ä¸ª gnn_rank æ–‡ä»¶ç»Ÿè®¡è¦†ç›–ç‡
    print('\n[2/2] ç»Ÿè®¡å„ gnn_rank æ–‡ä»¶çš„è¦†ç›–ç‡...')
    
    results = []  # åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä¸º {'topk': x, ...} çš„å­—å…¸
    
    total_files = sum(len(files) for files in files_by_topk.values())
    current_file = 0
    
    for i, topk in enumerate(topk_list, 1):
        # ç¡®ä¿ topk åœ¨ files_by_topk ä¸­ï¼ˆåº”è¯¥æ€»æ˜¯åœ¨ï¼Œä½†ä¸ºäº†å®‰å…¨ï¼‰
        if topk not in files_by_topk:
            print(f'âš ï¸ TopK={topk} ä¸åœ¨æ–‡ä»¶åˆ—è¡¨ä¸­ï¼Œè·³è¿‡')
            continue
        
        rank_files = files_by_topk[topk]
        
        for rank_file in sorted(rank_files):  # å¯¹æ¯ä¸ªæ–‡ä»¶éƒ½ç»Ÿè®¡
            current_file += 1
            filename = os.path.basename(rank_file)
            
            if topk is None:
                rank_tag = 'gnn_rank'
            elif topk == float('inf'):
                rank_tag = 'topk_all'
            else:
                rank_tag = f'topk{topk}'
            
            # è¯»å– gnn_rank æ–‡ä»¶ä¸­çš„èŠ‚ç‚¹åˆ—è¡¨
            # ç”±äºæ–‡ä»¶æœ¬èº«å·²ç»åŒ…å« topk ä¸ªèŠ‚ç‚¹ï¼Œç›´æ¥è¯»å–å…¨éƒ¨
            gnn_nodes = load_gnn_topk(rank_file, topk=10**9)
            
            # è¿‡æ»¤ï¼šåªä¿ç•™åœ¨ node_results ä¸­çš„èŠ‚ç‚¹
            filtered_nodes = [n for n in gnn_nodes if n in node_results]
            
            if not filtered_nodes:
                print(f'âš ï¸ [{current_file}/{total_files}] {rank_tag}: æ²¡æœ‰åŒ¹é…çš„èŠ‚ç‚¹ï¼Œè·³è¿‡')
                continue
            
            # ç»Ÿè®¡è¦†ç›–ç‡å’ŒRMSE
            detected_nodes = 0
            detected_faults = 0
            rmse_values = []
            
            for node in filtered_nodes:
                node_detected = False
                for fault_type in ['sa0', 'sa1']:
                    fault_result = node_results[node].get(fault_type)
                    if fault_result and fault_result.get('detected', False):
                        detected_faults += 1
                        node_detected = True
                    # æ”¶é›† RMSE å€¼
                    if fault_result and fault_result.get('status') == 'success':
                        rmse_val = fault_result.get('rmse', float('nan'))
                        if not math.isnan(rmse_val):
                            rmse_values.append(rmse_val)
                if node_detected:
                    detected_nodes += 1
            
            # è®¡ç®—è¦†ç›–ç‡
            total_faults = len(filtered_nodes) * 2
            node_cov = detected_nodes / len(filtered_nodes) * 100.0 if filtered_nodes else 0
            fault_cov = detected_faults / total_faults * 100.0 if total_faults else 0
            
            # è®¡ç®—å¹³å‡RMSE
            avg_rmse = sum(rmse_values) / len(rmse_values) if rmse_values else 0.0
            max_rmse = max(rmse_values) if rmse_values else 0.0
            
            results.append({
                'topk': topk,
                'fault_cov': fault_cov,
                'node_cov': node_cov,
                'tested_nodes': len(filtered_nodes),
                'detected_nodes': detected_nodes,
                'detected_faults': detected_faults,
                'avg_rmse': avg_rmse,
                'max_rmse': max_rmse,
                'rmse_count': len(rmse_values)
            })
            
            if current_file % 50 == 0 or current_file == total_files:
                print(f'  [{current_file}/{total_files}] {rank_tag}: èŠ‚ç‚¹={len(filtered_nodes)}, '
                      f'èŠ‚ç‚¹è¦†ç›–ç‡={node_cov:.2f}%, æ•…éšœè¦†ç›–ç‡={fault_cov:.2f}%')
    
    # 3) ä¿å­˜ç»Ÿè®¡ç»“æœåˆ° CSV
    RESULT_CSV = os.path.join(RESULTS_DIR, 'coverage_statistics.csv')
    print(f'\nä¿å­˜ç»Ÿè®¡ç»“æœåˆ°: {RESULT_CSV}')
    
    with open(RESULT_CSV, 'w', newline='', encoding='utf-8') as f:
        writer = csv.writer(f)
        
        # å†™å…¥åˆ—æ ‡é¢˜ï¼ˆå»æ‰ run åˆ—ï¼Œå› ä¸º gnn_ranks ç›®å½•ä¸‹çš„æ–‡ä»¶æ²¡æœ‰ runï¼‰
        header = ['topk', 'tested_nodes', 'fault_coverage(%)', 'node_coverage(%)', 'avg_rmse', 'max_rmse', 'escaped_nodes', 'escaped_faults']
        writer.writerow(header)
        
        # å†™å…¥æ¯ä¸ªæ–‡ä»¶çš„æ•°æ®ï¼ˆæ¯è¡Œä»£è¡¨ä¸€ä¸ª topk çš„æ–‡ä»¶ï¼‰
        for result in results:
            tested_nodes = result['tested_nodes']
            detected_nodes = result['detected_nodes']
            detected_faults = result['detected_faults']
            
            # è®¡ç®—é€ƒé€¸èŠ‚ç‚¹å’Œé€ƒé€¸æ•…éšœ
            escaped_nodes = tested_nodes - detected_nodes
            injected_faults = tested_nodes * 2
            escaped_faults = injected_faults - detected_faults
            
            # å¤„ç† topk æ˜¾ç¤º
            topk_display = result['topk']
            if topk_display is None:
                topk_display = 'plain'
            elif topk_display == float('inf'):
                topk_display = 'all'
            
            row = [
                topk_display,
                tested_nodes,
                f"{result['fault_cov']:.2f}",
                f"{result['node_cov']:.2f}",
                f"{result['avg_rmse']:.4f}",
                f"{result['max_rmse']:.4f}",
                str(escaped_nodes),
                str(escaped_faults)
            ]
            writer.writerow(row)
    
    elapsed_phase2 = time.time() - t0_phase2
    
    # è®¡ç®—æ•´ä½“RMSEç»Ÿè®¡
    all_avg_rmse = [res['avg_rmse'] for res in results if res['avg_rmse'] > 0]
    all_max_rmse = [res['max_rmse'] for res in results if res['max_rmse'] > 0]
    
    print('\n' + '='*70)
    print('é˜¶æ®µ2 å®Œæˆ - è¦†ç›–ç‡ç»Ÿè®¡')
    print('='*70)
    print(f'ç»Ÿè®¡çš„ topk æ•°é‡: {len(topk_list)}')
    print(f'TopK èŒƒå›´: {min(topk_list)} - {max(topk_list)}')
    print(f'æ€»æ–‡ä»¶æ•°: {len(results)}')
    print(f'ç»“æœæ–‡ä»¶: {RESULT_CSV}')
    
    if all_avg_rmse:
        print(f'\nğŸ“Š RMSE æ•´ä½“ç»Ÿè®¡ (è·¨æ‰€æœ‰ topk):')
        print(f'   å¹³å‡ RMSE èŒƒå›´: {min(all_avg_rmse):.4f} - {max(all_avg_rmse):.4f}')
        print(f'   æœ€å¤§ RMSE èŒƒå›´: {min(all_max_rmse):.4f} - {max(all_max_rmse):.4f}')
        print(f'   æ€»ä½“å¹³å‡ RMSE: {sum(all_avg_rmse)/len(all_avg_rmse):.4f}')
    
    print(f'\né˜¶æ®µ2ç”¨æ—¶: {elapsed_phase2:.2f}s')
    print('='*70)


# ========== ä¸»å‡½æ•° ==========

def main():
    print('='*70)
    print('å…¨èŠ‚ç‚¹æ•…éšœæ³¨å…¥ä¸è¦†ç›–ç‡ç»Ÿè®¡å·¥å…· (ä½¿ç”¨ gnn_ranks ç›®å½•)')
    print('='*70)
    print(f'ç½‘è¡¨æ–‡ä»¶: {VERILOG_SRC}')
    print(f'Testbench: {TB_FILE}')
    print(f'å·¥è‰ºåº“: {CELL_LIB}')
    print(f'Rank ç›®å½•: {RANK_DIR}')
    print(f'ç»“æœç›®å½•: {RESULTS_DIR}')
    print('='*70)
    
    t0_total = time.time()
    
    # æ£€æŸ¥ç»“æœæ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
    results_file = os.path.join(RESULTS_DIR, 'full_injection_results.json')
    golden_file = os.path.join(RESULTS_DIR, 'golden_result.json')
    
    if os.path.exists(results_file) and os.path.exists(golden_file):
        print('\nâš ï¸ æ£€æµ‹åˆ°å·²å­˜åœ¨çš„å…¨èŠ‚ç‚¹æ³¨å…¥ç»“æœ')
        user_input = input('æ˜¯å¦è·³è¿‡é˜¶æ®µ1ï¼Œç›´æ¥ä½¿ç”¨ç°æœ‰ç»“æœè¿›è¡Œç»Ÿè®¡ï¼Ÿ(y/n): ')
        if user_input.lower() == 'y':
            print('åŠ è½½ç°æœ‰ç»“æœ...')
            with open(golden_file, 'r', encoding='utf-8') as f:
                golden_data = json.load(f)
                golden_vals = golden_data['values']
            
            with open(results_file, 'r', encoding='utf-8') as f:
                node_results = json.load(f)
            
            print(f'âœ… å·²åŠ è½½ {len(node_results)} ä¸ªèŠ‚ç‚¹çš„æµ‹è¯•ç»“æœ')
            
            # ç›´æ¥è¿›å…¥é˜¶æ®µ2
            phase2_coverage_statistics(golden_vals, node_results)
            
            elapsed_total = time.time() - t0_total
            print(f'\nâ±ï¸ æ€»è¿è¡Œæ—¶é—´: {elapsed_total:.2f}s')
            return
    
    # é˜¶æ®µ1ï¼šå…¨èŠ‚ç‚¹æ³¨å…¥
    golden_vals, node_results = phase1_full_node_injection()
    
    if golden_vals is None or node_results is None:
        print('\nâŒ é˜¶æ®µ1å¤±è´¥ï¼Œç¨‹åºç»ˆæ­¢')
        return
    
    # é˜¶æ®µ2ï¼šè¦†ç›–ç‡ç»Ÿè®¡
    phase2_coverage_statistics(golden_vals, node_results)
    
    elapsed_total = time.time() - t0_total
    
    print('\n' + '='*70)
    print('å…¨éƒ¨å®Œæˆï¼')
    print('='*70)
    print(f'â±ï¸ æ€»è¿è¡Œæ—¶é—´: {elapsed_total:.2f}s')
    print(f'ğŸ“ ç»“æœä¿å­˜åœ¨: {RESULTS_DIR}/')
    print('='*70)


if __name__ == '__main__':
    main()


