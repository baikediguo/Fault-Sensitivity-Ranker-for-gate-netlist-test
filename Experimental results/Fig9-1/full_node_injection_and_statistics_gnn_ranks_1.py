# full_node_injection_and_statistics_gnn_ranks.py
# ä¸¤é˜¶æ®µæ•…éšœæ³¨å…¥ä¸ç»Ÿè®¡è„šæœ¬
# é˜¶æ®µ1ï¼šå¯¹ç½‘è¡¨æ‰€æœ‰èŠ‚ç‚¹è¿›è¡Œæ•…éšœæ³¨å…¥ï¼Œä¿å­˜æµ‹è¯•ç»“æœ
# é˜¶æ®µ2ï¼šæ ¹æ®ä¿å­˜çš„ç»“æœï¼Œå¯¹ä¸åŒgnn_rankæ–‡ä»¶çš„è¦†ç›–ç‡è¿›è¡Œç»Ÿè®¡
# ä½¿ç”¨ gnn_ranks ç›®å½•ï¼ˆæ–‡ä»¶åæ ¼å¼ï¼šgnn_rank_{topk}.txtï¼‰

import os
import re
import csv
import time
import json
import subprocess
from typing import List, Tuple, Set, Dict
import glob
from collections import defaultdict

## ===== åŸºæœ¬é…ç½® =====
VERILOG_SRC = 'pe.synth_dct.v'    # ç½‘è¡¨
TB_FILE     = 'tb_1.v'              # testbench
CELL_LIB    = 'cells.v'           # å·¥è‰ºåº“
RANK_DIR    = 'gnn_ranks_1'          # å­˜æ”¾å¤šä¸ª gnn_rank_xxx.txt çš„ç›®å½•

# æ—¥å¿—&ä¸´æ—¶æ–‡ä»¶ç›®å½•
LOGDIR = 'sim_logs_full_injection'
os.makedirs(LOGDIR, exist_ok=True)

# å…¨èŠ‚ç‚¹æ³¨å…¥ç»“æœä¿å­˜ç›®å½•
RESULTS_DIR = 'full_injection_results'
os.makedirs(RESULTS_DIR, exist_ok=True)

# æ³¨å…¥æ—¶åºé…ç½®
INJECT_DELAY_CYCLES = 5
MAX_VVP_SECONDS     = 60

# è¾“å‡ºåŒ¹é…æ¨¡å¼
OSUM_HEX_RE = re.compile(r'^o_sum=([0-9a-fA-FxzXZ]+)')

# å…è®¸çš„æœªçŸ¥æ¯”ä¾‹
MAX_UNKNOWN_RATIO = 0.2


# ========== å·¥å…·å‡½æ•° ==========

def run_cmd(cmd: List[str], capture=False, timeout=None) -> Tuple[int, str]:
    """æ‰§è¡Œå‘½ä»¤ï¼Œåœ¨ Windows ä¸‹ç”¨ UTF-8 å¹¶å¿½ç•¥ä¸èƒ½è§£ç çš„å­—ç¬¦"""
    if capture:
        proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT,
                                text=True, encoding='utf-8', errors='ignore')
        try:
            out, _ = proc.communicate(timeout=timeout)
        except subprocess.TimeoutExpired:
            proc.kill()
            return -1, 'TIMEOUT'
        return proc.returncode, out
    else:
        try:
            rc = subprocess.call(cmd)
            return rc, ''
        except Exception as e:
            return -1, str(e)


def strip_comments(text: str) -> str:
    """å»é™¤ Verilog æ³¨é‡Š"""
    text = re.sub(r'/\*.*?\*/', '', text, flags=re.DOTALL)
    text = re.sub(r'//.*', '', text)
    return text


def extract_module(text: str, modname: str) -> str:
    """æå–æ¨¡å—å®šä¹‰"""
    m = re.search(rf'\bmodule\s+{re.escape(modname)}\b.*?\bendmodule\b', text, flags=re.DOTALL)
    return m.group(0) if m else ''


def split_decl_names(decl_body: str) -> List[str]:
    """æ‹†åˆ†å£°æ˜ä¸­çš„ä¿¡å·å"""
    out = []
    decl_body = re.sub(r'\[[^]\n]*:[^]\n]*\]', '', decl_body)
    for chunk in decl_body.split(','):
        token = chunk.strip()
        if not token:
            continue
        m = re.match(r'^([A-Za-z_][A-Za-z0-9_$]*)(\[\d+\])?$', token)
        if m:
            out.append(m.group(0))
    return out


def parse_ports(module_text: str) -> Tuple[Set[str], Set[str], Set[str]]:
    """è§£ææ¨¡å—çš„è¾“å…¥ã€è¾“å‡ºã€åŒå‘ç«¯å£"""
    inputs, outputs, inouts = set(), set(), set()
    for stmt in module_text.split(';'):
        s = stmt.strip()
        if not s: continue
        if re.match(r'^\binput\b', s):
            body = re.sub(r'^\binput\b\s+((?:wire|reg|logic|signed|unsigned)\s+)*', '', s)
            inputs.update(split_decl_names(body))
        elif re.match(r'^\boutput\b', s):
            body = re.sub(r'^\boutput\b\s+((?:wire|reg|logic|signed|unsigned)\s+)*', '', s)
            outputs.update(split_decl_names(body))
        elif re.match(r'^\binout\b', s):
            body = re.sub(r'^\binout\b\s+((?:wire|reg|logic|signed|unsigned)\s+)*', '', s)
            inouts.update(split_decl_names(body))
    return inputs, outputs, inouts


def parse_internal_nets(module_text: str) -> Set[str]:
    """è§£ææ¨¡å—å†…éƒ¨çš„ wire/reg ä¿¡å·"""
    nets = set()
    for stmt in module_text.split(';'):
        s = stmt.strip()
        if not s: continue
        if re.match(r'^(wire|reg|logic)\b', s):
            body = re.sub(r'^(wire|reg|logic)\b\s+((?:signed|unsigned)\s+)?', '', s)
            nets.update(split_decl_names(body))
    return nets


def parse_targets_from_netlist(netlist_text: str, dut_module: str = 'pe') -> List[str]:
    """
    è§£æå¯æ³¨å…¥ç›®æ ‡ï¼šè¾“å‡ºç«¯å£ âˆª å†…éƒ¨ nets âˆ’ è¾“å…¥ç«¯å£
    ä»…ä¿ç•™å¯ force çš„åˆæ³•åå­—ï¼ˆID æˆ– ID[NUM]ï¼‰
    """
    text = strip_comments(netlist_text)
    mod = extract_module(text, dut_module)
    if not mod:
        mod = text
    inputs, outputs, _ = parse_ports(mod)
    internals = parse_internal_nets(mod)
    targets = (outputs | internals) - inputs

    good = []
    for n in sorted(targets):
        if re.match(r'^[A-Za-z_][A-Za-z0-9_$]*$', n) or re.match(r'^[A-Za-z_][A-Za-z0-9_$]*\[\d+\]$', n):
            good.append(n)
    return good


def make_injected_tb(tb_text: str, target_net: str, stuck: int) -> str:
    """ç”Ÿæˆå¸¦æ•…éšœæ³¨å…¥çš„ testbench"""
    inj_block = f"""
// --- fault injection block (auto) ---
initial begin : __fi_block
    wait (reset == 0);
    repeat({INJECT_DELAY_CYCLES}) @(posedge clock);
    force uut.{target_net} = 1'b{stuck};
    $display("FAULT_INJECTED: {target_net} sa{stuck}");
end
// --- end injection block ---
"""
    idx = tb_text.rfind('endmodule')
    if idx == -1:
        return tb_text + '\n' + inj_block
    else:
        return tb_text[:idx] + inj_block + tb_text[idx:]


def compile_and_run(sources: List[str], exe_path: str, vcd_path: str, log_path: str,
                    timeout: int = MAX_VVP_SECONDS) -> bool:
    """
    Icarus Verilog ç¼–è¯‘å’Œè¿è¡Œæµç¨‹
    è¿”å› True/False è¡¨ç¤ºæˆåŠŸ/å¤±è´¥
    """
    # ç¼–è¯‘
    cmd_compile = ['iverilog', '-g2012', '-o', exe_path] + [os.path.abspath(s) for s in sources]
    rc, out = run_cmd(cmd_compile, capture=True)
    if rc != 0:
        with open(log_path, 'w', encoding='utf-8', errors='ignore') as f:
            f.write(out)
        return False

    # è¿è¡Œ
    cmd_run = ['vvp', exe_path, f'+DUMPFILE={vcd_path}']
    with open(log_path, 'w', encoding='utf-8', errors='ignore') as f:
        try:
            proc = subprocess.Popen(cmd_run, stdout=f, stderr=subprocess.STDOUT,
                                    text=True, encoding='utf-8', errors='ignore')
            proc.wait(timeout=timeout)
        except subprocess.TimeoutExpired:
            proc.kill()
            f.write('\n[ERROR] vvp TIMEOUT\n')
            return False

    return True


def parse_osum_as_ints(logfile: str) -> Tuple[List[int], float]:
    """ä»æ—¥å¿—æ–‡ä»¶ä¸­è§£æ o_sum è¾“å‡ºå€¼"""
    vals, total, unknown = [], 0, 0
    try:
        with open(logfile, 'r', encoding='utf-8', errors='ignore') as f:
            for line in f:
                m = OSUM_HEX_RE.match(line.strip())
                if not m:
                    continue
                total += 1
                s = m.group(1).lower()
                if 'x' in s or 'z' in s:
                    unknown += 1
                    continue
                try:
                    vals.append(int(s, 16))
                except ValueError:
                    unknown += 1
    except Exception as e:
        print(f'âš ï¸ è¯»å– {logfile} å¤±è´¥: {e}')
    unk_ratio = (unknown / total) if total > 0 else 1.0
    return vals, unk_ratio


def load_gnn_topk(path: str, topk: int) -> List[str]:
    """ä» gnn_rank æ–‡ä»¶ä¸­è¯»å–å‰ topk ä¸ªèŠ‚ç‚¹"""
    if not os.path.exists(path):
        print(f'âŒ æœªæ‰¾åˆ° {path}')
        return []
    nodes = []
    with open(path, 'r', encoding='utf-8', errors='ignore') as f:
        for line in f:
            line = line.strip()
            if not line: continue
            parts = line.split()
            if len(parts) >= 1:
                nodes.append(parts[0])
    return nodes[:topk]


def extract_topk(filename: str) -> int:
    """ä»æ–‡ä»¶åæå– TopK æ•°å­—ï¼Œä¾‹å¦‚ gnn_rank_50.txt -> 50"""
    # æ”¯æŒæ ¼å¼ï¼šgnn_rank_50.txt
    m = re.search(r'gnn_rank_(\d+)\.txt', filename)
    if m:
        return int(m.group(1))
    # ä¹Ÿæ”¯æŒ gnn_rank_all.txt æ ¼å¼
    m2 = re.search(r'gnn_rank_all\.txt', filename)
    if m2:
        return float('inf')  # è¡¨ç¤ºå…¨éƒ¨èŠ‚ç‚¹
    return float('inf')


# ========== é˜¶æ®µ1ï¼šå…¨èŠ‚ç‚¹æ³¨å…¥ ==========

def phase1_full_node_injection():
    """
    é˜¶æ®µ1ï¼šå¯¹ç½‘è¡¨æ‰€æœ‰èŠ‚ç‚¹è¿›è¡Œæ•…éšœæ³¨å…¥æµ‹è¯•ï¼Œå¹¶ä¿å­˜æ¯ä¸ªèŠ‚ç‚¹çš„æµ‹è¯•ç»“æœ
    è¿”å›ï¼šgolden å€¼åˆ—è¡¨å’Œå…¨èŠ‚ç‚¹æµ‹è¯•ç»“æœå­—å…¸
    """
    print('\n' + '='*70)
    print('é˜¶æ®µ1ï¼šå…¨èŠ‚ç‚¹æ•…éšœæ³¨å…¥æµ‹è¯•')
    print('='*70)
    
    t0_phase1 = time.time()
    
    # 1) ç”Ÿæˆ golden åŸºå‡†
    print('\n[1/3] è¿è¡Œ golden ä»¿çœŸï¼ˆæ— æ•…éšœåŸºå‡†ï¼‰...')
    golden_exe = os.path.join(LOGDIR, 'golden.out')
    golden_vcd = os.path.join(LOGDIR, 'golden.vcd')
    golden_log = os.path.join(LOGDIR, 'golden.log')
    ok = compile_and_run([CELL_LIB, VERILOG_SRC, TB_FILE],
                         golden_exe, golden_vcd, golden_log,
                         timeout=MAX_VVP_SECONDS)
    if not ok:
        print('âŒ Golden ä»¿çœŸå¤±è´¥')
        with open(golden_log, 'r', encoding='utf-8', errors='ignore') as f:
            print(f.read())
        return None, None
    
    golden_vals, golden_unk = parse_osum_as_ints(golden_log)
    if not golden_vals:
        print('âŒ golden.log æ²¡æœ‰æœ‰æ•ˆçš„ o_sum æ ·æœ¬')
        return None, None
    print(f'âœ… Golden æ ·æœ¬æ•°: {len(golden_vals)}, Unknownæ¯”ä¾‹: {golden_unk:.2%}')
    
    # ä¿å­˜ golden ç»“æœ
    golden_result_file = os.path.join(RESULTS_DIR, 'golden_result.json')
    with open(golden_result_file, 'w', encoding='utf-8') as f:
        json.dump({
            'values': golden_vals,
            'unknown_ratio': golden_unk,
            'sample_count': len(golden_vals)
        }, f, indent=2)
    print(f'âœ… Golden ç»“æœå·²ä¿å­˜: {golden_result_file}')
    
    # 2) è§£ææ‰€æœ‰å¯æ³¨å…¥çš„åˆæ³•èŠ‚ç‚¹
    print('\n[2/3] è§£æç½‘è¡¨ä¸­çš„å¯æ³¨å…¥èŠ‚ç‚¹...')
    with open(VERILOG_SRC, 'r', encoding='utf-8', errors='ignore') as f:
        net_text = f.read()
    all_targets = parse_targets_from_netlist(net_text, dut_module='pe')
    
    # è¿‡æ»¤æ‰æ—¶é’Ÿå’Œå¤ä½ä¿¡å·
    legal_targets = [n for n in all_targets 
                     if not re.match(r'^(clk|clock|rst|reset)', n, flags=re.IGNORECASE)]
    
    print(f'âœ… å…±æ‰¾åˆ° {len(legal_targets)} ä¸ªå¯æ³¨å…¥èŠ‚ç‚¹ï¼ˆå·²è¿‡æ»¤æ—¶é’Ÿå’Œå¤ä½ä¿¡å·ï¼‰')
    
    # ä¿å­˜èŠ‚ç‚¹åˆ—è¡¨
    nodes_list_file = os.path.join(RESULTS_DIR, 'all_nodes.txt')
    with open(nodes_list_file, 'w', encoding='utf-8') as f:
        for node in legal_targets:
            f.write(f'{node}\n')
    print(f'âœ… èŠ‚ç‚¹åˆ—è¡¨å·²ä¿å­˜: {nodes_list_file}')
    
    # 3) å¯¹æ¯ä¸ªèŠ‚ç‚¹è¿›è¡Œ SA0 å’Œ SA1 æ³¨å…¥
    print('\n[3/3] å¼€å§‹å…¨èŠ‚ç‚¹æ³¨å…¥æµ‹è¯•...')
    print(f'æ€»å…±éœ€è¦æµ‹è¯•: {len(legal_targets)} ä¸ªèŠ‚ç‚¹ Ã— 2 ç§æ•…éšœç±»å‹ = {len(legal_targets)*2} æ¬¡ä»¿çœŸ')
    
    tb_src = open(TB_FILE, 'r', encoding='utf-8', errors='ignore').read()
    
    # å­˜å‚¨æ¯ä¸ªèŠ‚ç‚¹çš„æµ‹è¯•ç»“æœ
    node_results = {}  # {node_name: {'sa0': {...}, 'sa1': {...}}}
    
    total_tests = len(legal_targets) * 2
    current_test = 0
    
    for i, net in enumerate(legal_targets, 1):
        node_results[net] = {'sa0': None, 'sa1': None}
        
        for val in [0, 1]:
            current_test += 1
            fault_type = f'sa{val}'
            
            # æ˜¾ç¤ºè¿›åº¦
            if current_test % 100 == 0 or current_test == total_tests:
                elapsed = time.time() - t0_phase1
                progress = current_test / total_tests * 100
                print(f'  è¿›åº¦: [{current_test}/{total_tests}] ({progress:.1f}%) '
                      f'å½“å‰èŠ‚ç‚¹: {net} {fault_type} - å·²ç”¨æ—¶: {elapsed:.1f}s')
            
            # ç”Ÿæˆæ³¨å…¥ testbench
            tb_inj = make_injected_tb(tb_src, net, val)
            tb_tmp = os.path.join(LOGDIR, f'tb_inj_{i}_{fault_type}.v')
            with open(tb_tmp, 'w', encoding='utf-8', errors='ignore') as w:
                w.write(tb_inj)
            
            # ç¼–è¯‘å’Œè¿è¡Œ
            exe = os.path.join(LOGDIR, f'sim_{i}_{fault_type}.out')
            vcd = os.path.join(LOGDIR, f'sim_{i}_{fault_type}.vcd')
            log = os.path.join(LOGDIR, f'sim_{i}_{fault_type}.log')
            
            ok = compile_and_run([CELL_LIB, VERILOG_SRC, tb_tmp], 
                                exe, vcd, log, timeout=MAX_VVP_SECONDS)
            
            if not ok:
                node_results[net][fault_type] = {
                    'status': 'compile_fail',
                    'detected': False,
                    'values': [],
                    'unknown_ratio': 1.0
                }
                continue
            
            # è§£æç»“æœ
            vals, unk = parse_osum_as_ints(log)
            
            if not vals or unk > MAX_UNKNOWN_RATIO:
                node_results[net][fault_type] = {
                    'status': 'invalid_output',
                    'detected': False,
                    'values': vals,
                    'unknown_ratio': unk
                }
                continue
            
            # å¯¹æ¯” golden å€¼åˆ¤æ–­æ˜¯å¦æ£€æµ‹åˆ°æ•…éšœ
            L = min(len(golden_vals), len(vals))
            diff_count = sum(1 for a, b in zip(golden_vals[:L], vals[:L]) if a != b)
            detected = diff_count > 0
            
            node_results[net][fault_type] = {
                'status': 'success',
                'detected': detected,
                'diff_count': diff_count,
                'sample_count': L,
                'values': vals,
                'unknown_ratio': unk
            }
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶ï¼ˆä¿ç•™ logï¼Œåˆ é™¤ exe å’Œ vcdï¼‰
            try:
                if os.path.exists(tb_tmp):
                    os.remove(tb_tmp)
                if os.path.exists(exe):
                    os.remove(exe)
                if os.path.exists(vcd):
                    os.remove(vcd)
            except Exception as e:
                pass
    
    # ä¿å­˜å®Œæ•´æµ‹è¯•ç»“æœ
    results_file = os.path.join(RESULTS_DIR, 'full_injection_results.json')
    print(f'\nä¿å­˜æµ‹è¯•ç»“æœåˆ°: {results_file}')
    with open(results_file, 'w', encoding='utf-8') as f:
        # ç”±äºç»“æœå¯èƒ½å¾ˆå¤§ï¼Œä¸ä¿å­˜å…·ä½“çš„ valuesï¼Œåªä¿å­˜æ£€æµ‹çŠ¶æ€
        simplified_results = {}
        for node, faults in node_results.items():
            simplified_results[node] = {
                'sa0': {k: v for k, v in faults['sa0'].items() if k != 'values'} if faults['sa0'] else None,
                'sa1': {k: v for k, v in faults['sa1'].items() if k != 'values'} if faults['sa1'] else None
            }
        json.dump(simplified_results, f, indent=2)
    
    # ç»Ÿè®¡æ±‡æ€»
    total_nodes = len(legal_targets)
    total_faults = total_nodes * 2
    detected_nodes = 0
    detected_faults = 0
    
    for node, faults in node_results.items():
        node_detected = False
        for fault_type in ['sa0', 'sa1']:
            if faults[fault_type] and faults[fault_type].get('detected', False):
                detected_faults += 1
                node_detected = True
        if node_detected:
            detected_nodes += 1
    
    elapsed_phase1 = time.time() - t0_phase1
    
    print('\n' + '='*70)
    print('é˜¶æ®µ1 å®Œæˆ - å…¨èŠ‚ç‚¹æ³¨å…¥æµ‹è¯•ç»Ÿè®¡')
    print('='*70)
    print(f'æ€»æµ‹è¯•èŠ‚ç‚¹æ•°: {total_nodes}')
    print(f'æ€»æµ‹è¯•æ•…éšœæ•°: {total_faults}')
    print(f'æ£€æµ‹åˆ°çš„èŠ‚ç‚¹æ•°: {detected_nodes} ({detected_nodes/total_nodes*100:.2f}%)')
    print(f'æ£€æµ‹åˆ°çš„æ•…éšœæ•°: {detected_faults} ({detected_faults/total_faults*100:.2f}%)')
    print(f'\né˜¶æ®µ1æ€»ç”¨æ—¶: {elapsed_phase1:.2f}s')
    print('='*70)
    
    return golden_vals, node_results


# ========== é˜¶æ®µ2ï¼šåŸºäºä¿å­˜ç»“æœçš„è¦†ç›–ç‡ç»Ÿè®¡ ==========

def phase2_coverage_statistics(golden_vals: List[int], node_results: Dict):
    """
    é˜¶æ®µ2ï¼šæ ¹æ®ä¿å­˜çš„å…¨èŠ‚ç‚¹æµ‹è¯•ç»“æœï¼Œå¯¹ä¸åŒ gnn_rank æ–‡ä»¶çš„è¦†ç›–ç‡è¿›è¡Œç»Ÿè®¡
    gnn_ranks ç›®å½•ä¸‹çš„æ–‡ä»¶æ ¼å¼ï¼šgnn_rank_{topk}.txtï¼ˆæ²¡æœ‰ run åç¼€ï¼‰
    """
    print('\n' + '='*70)
    print('é˜¶æ®µ2ï¼šåŸºäºå…¨èŠ‚ç‚¹ç»“æœçš„è¦†ç›–ç‡ç»Ÿè®¡')
    print('='*70)
    
    t0_phase2 = time.time()
    
    # 1) æŸ¥æ‰¾æ‰€æœ‰ gnn_rank æ–‡ä»¶
    print('\n[1/2] æŸ¥æ‰¾ gnn_rank æ–‡ä»¶...')
    rank_files = glob.glob(os.path.join(RANK_DIR, "gnn_rank_*.txt"))
    if not rank_files:
        print(f'âŒ {RANK_DIR} ä¸‹æ²¡æœ‰ gnn_rank_*.txt æ–‡ä»¶')
        return
    
    # æŒ‰ topk åˆ†ç»„
    files_by_topk = {}  # {topk: [filepath]}
    for filepath in rank_files:
        filename = os.path.basename(filepath)
        topk = extract_topk(filename)
        if topk != float('inf'):
            if topk not in files_by_topk:
                files_by_topk[topk] = []
            files_by_topk[topk].append(filepath)
    
    # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
    for topk, files in sorted(files_by_topk.items()):
        print(f'  TopK={topk}: æ‰¾åˆ° {len(files)} ä¸ªæ’åæ–‡ä»¶')
    
    if not files_by_topk:
        print('âŒ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„æ’åæ–‡ä»¶')
        return
    
    # ä½¿ç”¨ files_by_topk çš„ key ç¡®ä¿ä¸€è‡´æ€§
    topk_list = sorted(files_by_topk.keys())
    print(f'âœ… æ‰¾åˆ° {len(topk_list)} ä¸ª topk å€¼: {topk_list}')
    
    # 2) å¯¹æ¯ä¸ª gnn_rank æ–‡ä»¶ç»Ÿè®¡è¦†ç›–ç‡
    print('\n[2/2] ç»Ÿè®¡å„ gnn_rank æ–‡ä»¶çš„è¦†ç›–ç‡...')
    
    results = []  # åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä¸º {'topk': x, ...} çš„å­—å…¸
    
    total_files = sum(len(files) for files in files_by_topk.values())
    current_file = 0
    
    for i, topk in enumerate(topk_list, 1):
        # ç¡®ä¿ topk åœ¨ files_by_topk ä¸­ï¼ˆåº”è¯¥æ€»æ˜¯åœ¨ï¼Œä½†ä¸ºäº†å®‰å…¨ï¼‰
        if topk not in files_by_topk:
            print(f'âš ï¸ TopK={topk} ä¸åœ¨æ–‡ä»¶åˆ—è¡¨ä¸­ï¼Œè·³è¿‡')
            continue
        
        rank_files = files_by_topk[topk]
        
        for rank_file in sorted(rank_files):  # å¯¹æ¯ä¸ªæ–‡ä»¶éƒ½ç»Ÿè®¡
            current_file += 1
            filename = os.path.basename(rank_file)
            
            rank_tag = f'topk{topk}'
            
            # è¯»å– gnn_rank æ–‡ä»¶ä¸­çš„èŠ‚ç‚¹åˆ—è¡¨
            # ç”±äºæ–‡ä»¶æœ¬èº«å·²ç»åŒ…å« topk ä¸ªèŠ‚ç‚¹ï¼Œç›´æ¥è¯»å–å…¨éƒ¨
            gnn_nodes = load_gnn_topk(rank_file, topk=10**9)
            
            # è¿‡æ»¤ï¼šåªä¿ç•™åœ¨ node_results ä¸­çš„èŠ‚ç‚¹
            filtered_nodes = [n for n in gnn_nodes if n in node_results]
            
            if not filtered_nodes:
                print(f'âš ï¸ [{current_file}/{total_files}] {rank_tag}: æ²¡æœ‰åŒ¹é…çš„èŠ‚ç‚¹ï¼Œè·³è¿‡')
                continue
            
            # ç»Ÿè®¡è¦†ç›–ç‡
            detected_nodes = 0
            detected_faults = 0
            
            for node in filtered_nodes:
                node_detected = False
                for fault_type in ['sa0', 'sa1']:
                    fault_result = node_results[node].get(fault_type)
                    if fault_result and fault_result.get('detected', False):
                        detected_faults += 1
                        node_detected = True
                if node_detected:
                    detected_nodes += 1
            
            # è®¡ç®—è¦†ç›–ç‡
            total_faults = len(filtered_nodes) * 2
            node_cov = detected_nodes / len(filtered_nodes) * 100.0 if filtered_nodes else 0
            fault_cov = detected_faults / total_faults * 100.0 if total_faults else 0
            
            results.append({
                'topk': topk,
                'fault_cov': fault_cov,
                'node_cov': node_cov,
                'tested_nodes': len(filtered_nodes),
                'detected_nodes': detected_nodes,
                'detected_faults': detected_faults
            })
            
            if current_file % 50 == 0 or current_file == total_files:
                print(f'  [{current_file}/{total_files}] {rank_tag}: èŠ‚ç‚¹={len(filtered_nodes)}, '
                      f'èŠ‚ç‚¹è¦†ç›–ç‡={node_cov:.2f}%, æ•…éšœè¦†ç›–ç‡={fault_cov:.2f}%')
    
    # 3) ä¿å­˜ç»Ÿè®¡ç»“æœåˆ° CSV
    RESULT_CSV = os.path.join(RESULTS_DIR, 'coverage_statistics.csv')
    print(f'\nä¿å­˜ç»Ÿè®¡ç»“æœåˆ°: {RESULT_CSV}')
    
    with open(RESULT_CSV, 'w', newline='', encoding='utf-8') as f:
        writer = csv.writer(f)
        
        # å†™å…¥åˆ—æ ‡é¢˜ï¼ˆå»æ‰ run åˆ—ï¼Œå› ä¸º gnn_ranks ç›®å½•ä¸‹çš„æ–‡ä»¶æ²¡æœ‰ runï¼‰
        header = ['topk', 'tested_nodes', 'fault_coverage(%)', 'node_coverage(%)', 'escaped_nodes', 'escaped_faults']
        writer.writerow(header)
        
        # å†™å…¥æ¯ä¸ªæ–‡ä»¶çš„æ•°æ®ï¼ˆæ¯è¡Œä»£è¡¨ä¸€ä¸ª topk çš„æ–‡ä»¶ï¼‰
        for result in results:
            tested_nodes = result['tested_nodes']
            detected_nodes = result['detected_nodes']
            detected_faults = result['detected_faults']
            
            # è®¡ç®—é€ƒé€¸èŠ‚ç‚¹å’Œé€ƒé€¸æ•…éšœ
            escaped_nodes = tested_nodes - detected_nodes
            injected_faults = tested_nodes * 2
            escaped_faults = injected_faults - detected_faults
            
            row = [
                result['topk'],
                tested_nodes,
                f"{result['fault_cov']:.2f}",
                f"{result['node_cov']:.2f}",
                str(escaped_nodes),
                str(escaped_faults)
            ]
            writer.writerow(row)
    
    elapsed_phase2 = time.time() - t0_phase2
    
    print('\n' + '='*70)
    print('é˜¶æ®µ2 å®Œæˆ - è¦†ç›–ç‡ç»Ÿè®¡')
    print('='*70)
    print(f'ç»Ÿè®¡çš„ topk æ•°é‡: {len(topk_list)}')
    print(f'TopK èŒƒå›´: {min(topk_list)} - {max(topk_list)}')
    print(f'æ€»æ–‡ä»¶æ•°: {len(results)}')
    print(f'ç»“æœæ–‡ä»¶: {RESULT_CSV}')
    print(f'\né˜¶æ®µ2ç”¨æ—¶: {elapsed_phase2:.2f}s')
    print('='*70)


# ========== ä¸»å‡½æ•° ==========

def main():
    print('='*70)
    print('å…¨èŠ‚ç‚¹æ•…éšœæ³¨å…¥ä¸è¦†ç›–ç‡ç»Ÿè®¡å·¥å…· (ä½¿ç”¨ gnn_ranks ç›®å½•)')
    print('='*70)
    print(f'ç½‘è¡¨æ–‡ä»¶: {VERILOG_SRC}')
    print(f'Testbench: {TB_FILE}')
    print(f'å·¥è‰ºåº“: {CELL_LIB}')
    print(f'Rank ç›®å½•: {RANK_DIR}')
    print(f'ç»“æœç›®å½•: {RESULTS_DIR}')
    print('='*70)
    
    t0_total = time.time()
    
    # æ£€æŸ¥ç»“æœæ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
    results_file = os.path.join(RESULTS_DIR, 'full_injection_results.json')
    golden_file = os.path.join(RESULTS_DIR, 'golden_result.json')
    
    if os.path.exists(results_file) and os.path.exists(golden_file):
        print('\nâš ï¸ æ£€æµ‹åˆ°å·²å­˜åœ¨çš„å…¨èŠ‚ç‚¹æ³¨å…¥ç»“æœ')
        user_input = input('æ˜¯å¦è·³è¿‡é˜¶æ®µ1ï¼Œç›´æ¥ä½¿ç”¨ç°æœ‰ç»“æœè¿›è¡Œç»Ÿè®¡ï¼Ÿ(y/n): ')
        if user_input.lower() == 'y':
            print('åŠ è½½ç°æœ‰ç»“æœ...')
            with open(golden_file, 'r', encoding='utf-8') as f:
                golden_data = json.load(f)
                golden_vals = golden_data['values']
            
            with open(results_file, 'r', encoding='utf-8') as f:
                node_results = json.load(f)
            
            print(f'âœ… å·²åŠ è½½ {len(node_results)} ä¸ªèŠ‚ç‚¹çš„æµ‹è¯•ç»“æœ')
            
            # ç›´æ¥è¿›å…¥é˜¶æ®µ2
            phase2_coverage_statistics(golden_vals, node_results)
            
            elapsed_total = time.time() - t0_total
            print(f'\nâ±ï¸ æ€»è¿è¡Œæ—¶é—´: {elapsed_total:.2f}s')
            return
    
    # é˜¶æ®µ1ï¼šå…¨èŠ‚ç‚¹æ³¨å…¥
    golden_vals, node_results = phase1_full_node_injection()
    
    if golden_vals is None or node_results is None:
        print('\nâŒ é˜¶æ®µ1å¤±è´¥ï¼Œç¨‹åºç»ˆæ­¢')
        return
    
    # é˜¶æ®µ2ï¼šè¦†ç›–ç‡ç»Ÿè®¡
    phase2_coverage_statistics(golden_vals, node_results)
    
    elapsed_total = time.time() - t0_total
    
    print('\n' + '='*70)
    print('å…¨éƒ¨å®Œæˆï¼')
    print('='*70)
    print(f'â±ï¸ æ€»è¿è¡Œæ—¶é—´: {elapsed_total:.2f}s')
    print(f'ğŸ“ ç»“æœä¿å­˜åœ¨: {RESULTS_DIR}/')
    print('='*70)


if __name__ == '__main__':
    main()


